{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDU2T7TN6Lzn92zEwnJ78s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hydracsnova13/SRISHTI-24_IHUB_DATA-Internship-Projects/blob/main/run_inferencing_on_trained_model_OPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khwd6hw8ZGGX",
        "outputId": "ee7c1610-65fc-4fe3-db07-377e06bad114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"facebook/opt-125m\"  # Example model; adjust the model size as needed\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "030aa13389c0473e8985808c6c8ef538",
            "23d82bf9682b4d4b82abe079ff89f83b",
            "bc3ac924a75842e3a674e14b93613118",
            "245ec736416f4b3c856de6f0908b9888",
            "97dc568935e148bc9d4298d606dcd82b",
            "4385b60b1ad54c05a2093ebf778f045b",
            "9ec6c5d270f54c7f867faecd0f319d93",
            "0db84c7af08743a58a9facd1d77ac43e",
            "e1b76177474a48f7a1f0566db9ed3b27",
            "316bed2759bf4a8d9ed5b3ba5418ca97",
            "3861f062810649ccbe80caf1fbbe42b9",
            "0ab0b731476e40cfadb79d6550cd4977",
            "e95e9f66ed184b08b6214230d1e80c0d",
            "016fbf8c8b1b40a796b25f6b44f18f8d",
            "737acd2b05b248bb89d6ef53c564b56f",
            "fcdbcc1955064f9aa46be5037b8550c4",
            "8b699625ddb24af6af9ccbd048f7c36c",
            "3d2af35599cd4cd2913468153de01e92",
            "11e7aac75e344d13910f194d4162cfc1",
            "9f2e0b2c9b364f84bccbd2496b37dc4f",
            "8aeaa144367c4215a4ab3aca6a66987b",
            "cecc68098b3b43588955ca1e5cefb903",
            "c879d3f0a898491399a433283758c19a",
            "40a1c01778e943bd82cfb70cf5b9e148",
            "405b22a5cd2545dca8ca8823f61fdf30",
            "d88be99d6724411ea05030578c92f9bf",
            "80b702b57f9c4c5f86e63e02527ab2ca",
            "beb7aa891ef8410ebe186d490957fe6e",
            "29c8f316e9fc4994b7bf2913bbf3c487",
            "e66c3fdc3b794c72a21a3c76d8215b86",
            "53c8ddec7a1b450680e25e300b686fb3",
            "64b9978a9ec04777a10f343f456e3324",
            "b618e65468a94028bd19692811b8bd65",
            "1eed1066051f415b8fc3fa4220b2d2ed",
            "16d0e507cf1543ed825483d4a93c2751",
            "3dd430afbec742c79ca9cc5d4ce0f81d",
            "e531fd31401e43388fc4fb40f4d65906",
            "c0199377820740b8b6ccc7bb3e6016d4",
            "86478f103e1f400ba60337207aa7508e",
            "88cceb691c1b41cb8f5e238ea9878431",
            "eff348730a164b2b86d66eb766c1b472",
            "941e46fd119a4b90baeb76c24badb55c",
            "7a6b7f1758ec46f081d53cf6a775563b",
            "014d97a656444adf8cb20331320ff91f",
            "c3e09002e48547278d2e14b3d60bf8e6",
            "1d582f108f354daeb2ffa2eca86fab1e",
            "9dbbc9db0fed439d87e6eec32629927b",
            "1b9650cd731047ae8ecb86a0edfeef54",
            "a7fa427f2d604aea8838492de9397a49",
            "d4508440062342f49a792320cf2bc75c",
            "cc86f2776a034ae4b4ef54a9e1e4b751",
            "88f424af88ff4f088ef6fcd038e535c3",
            "d73eb06a4cf740b3a7ed50a016694ae6",
            "8b78e84a5c604095bd3fe5ec6b904776",
            "23052862d2be4f00a78a4865b0681c2a",
            "fc68a03899b348d494ff5da18566ba8f",
            "2a2769f53a9847e7a567fcac7c7ef81e",
            "f1f1590f68da4a59bd43f404fd5ba419",
            "750c8dec18894d59acbe9d3674cfbb8e",
            "3c9ba2c2a7144ef79b1ae002a1efe868",
            "1bc90af070aa4d7f9cb919c9f53627fe",
            "f8f754b6c04c4c899d3cdaccc32802dd",
            "f469729ad9ca4bc8a507e976cdaae871",
            "eddf694588a64b0bb1fb4404056fccd3",
            "ca77d76e336f43dd87350cf9f77f2ef9",
            "4ac2e83f24304660a809899fbc7b4f23",
            "6be0584d45c84513a79dde583e12b298",
            "0d5916356edd4cb6b828c14ad647a75d",
            "3f6d3e5e7f0044a58540251bb22b5d11",
            "f2eeb9072c3a400894aca8b46a4a4554",
            "889327318e1a4a4dad73f528d8746419",
            "16253ad43a334332bc659d34e3ac5aa4",
            "5d0fe6f8cdec4eaf84d025bee1d7fc28",
            "d4506b0dee1847c89c9a3618ed8a6be1",
            "d45c3582f3584d11810dab5c26b9f585",
            "71f216a7299f49e4baa4a912b422436b",
            "19801ff338fe46b2860d1e7cb114d723"
          ]
        },
        "id": "6QXQzEuaZKmU",
        "outputId": "6e33398a-91b2-4521-a1e3-003968285a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "030aa13389c0473e8985808c6c8ef538"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/651 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ab0b731476e40cfadb79d6550cd4977"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c879d3f0a898491399a433283758c19a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1eed1066051f415b8fc3fa4220b2d2ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3e09002e48547278d2e14b3d60bf8e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/251M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc68a03899b348d494ff5da18566ba8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6be0584d45c84513a79dde583e12b298"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"how to make a cake?\"  # Example prompt\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate text\n",
        "generated_ids = model.generate(\n",
        "    input_ids,\n",
        "    max_length=200,  # Shorten max length to focus output\n",
        "    num_return_sequences=1,\n",
        "    temperature=0.7,  # Lower temperature to make the model more confident in its choices\n",
        "    top_k=50,  # Use top-k sampling\n",
        "    top_p=0.95,  # Use nucleus sampling\n",
        "    no_repeat_ngram_size=4 # Prevent repeating the same n-grams\n",
        ")\n",
        "generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print(generated_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t44n40_RhzJh",
        "outputId": "a44ca9aa-024b-401c-b0ec-d7e095d8b896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "how to make a cake?\n",
            "\n",
            "I’m a baker and I’m trying to make a simple cake. I’ve been making cakes for a while now and I‘m not sure if I’ll ever be able to make a good cake. I have a few ideas for you to try.\n",
            "\n",
            "1. Make a cake with a little bit of butter.\n",
            "\n",
            "2. Make a little bit more butter.\n",
            "3. Make a bit more butter and bake it.\n",
            "4. Make a lot of butter and bake the cake.\n",
            "5. Make a bunch of butter and make a bunch of cake.\n",
            "6. Make a few butter and bake them.\n",
            "7. Make a couple of butter and let it sit for a while.\n",
            "8. Make a cupcake and bake it for a while and let it cool.\n",
            "9. Make a big cake and bake it in the oven for a while, and let it rest\n"
          ]
        }
      ]
    }
  ]
}